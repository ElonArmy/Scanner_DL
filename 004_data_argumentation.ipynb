{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-NET page-segmentation 학습이미지 데이터 증강\n",
    "- tf api의 image 클래스활용\n",
    "- 이미지 데이터 증강기법(https://www.tensorflow.org/addons/tutorials/image_ops?hl=ko)\n",
    "  - tfa.image.rotate : 단순 회전(2D)\n",
    "  - tfa.image.transform : 벡터기반으로 회전(3D)\n",
    "  - tfa.Random HSV in YIQ : 색상스케일, 색조, 채도등 무작위 지정 \n",
    "  - tf.image.flip_left_right : 상하 또는 좌우 뒤집기\n",
    "  - tf.image.rgb_to_grayscale : 그레이 스케일로 변환\n",
    "  - tf.image.adjust_saturation : 채도 조정\n",
    "  - tf.image.adjust_brightness : 밝기 변환 \n",
    "  - 위의 데이터는 수동으로 조정한다.\n",
    "  - tf.image.stateless_random_brightness 등을 활용하면 랜덤으로 선택되어 변환\n",
    "- 학습데이터의 세그먼테이션 라벨 이미지도 같은 랜덤시드로 증강해주어야 짝이 맞게 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras.backend as k\n",
    "\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n",
      "Getting test images ... \n",
      "Preparing is Done!\n"
     ]
    }
   ],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 1\n",
    "threshold_value = 50\n",
    "\n",
    "\n",
    "#데이터 경로 지정  \n",
    "TRAIN_PATH = './page_data/train/'\n",
    "TEST_PATH = './page_data/test/'\n",
    "\n",
    "# UserWarning을 무시하는 설정(없음 OK)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "\n",
    "#이미지 파일명을 리스트 형식으로 리턴  \n",
    "train_imgs = glob.glob(TRAIN_PATH+'ori/*.jpg')\n",
    "train_masks = glob.glob(TRAIN_PATH+'label/*.jpg')\n",
    "test_imgs = glob.glob(TEST_PATH+'ori/*.jpg')\n",
    "test_masks = glob.glob(TEST_PATH+'label/*.jpg')\n",
    "\n",
    "\n",
    "#리스트 길이 리턴  \n",
    "num_of_train_imgs = len(train_imgs)\n",
    "num_of_train_masks = len(train_masks)\n",
    "if num_of_train_imgs != num_of_train_masks:\n",
    "    print('invalid datasets, please check train data')\n",
    "    \n",
    "#각이미지를 배열로 리턴\n",
    "#image \n",
    "X_train = np.zeros((num_of_train_imgs, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "# mask\n",
    "Y_train = np.zeros((num_of_train_masks, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "# 이미지 리사이즈 후 리쉐이프\n",
    "for n in range(num_of_train_imgs):\n",
    "    img = imread(train_imgs[n], as_gray=True)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    # 특정 값보다 작은 모든 값을 0로 설정\n",
    "    img[img < threshold_value] = 0\n",
    "    img_resized = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img_resized.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "    mask = imread(train_masks[n], as_gray=True)\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "    mask[mask < threshold_value] = 0\n",
    "    mask_resized = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    Y_train[n] = mask_resized.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    \n",
    "# 테스트 이미지를 배열로 리턴\n",
    "X_test = np.zeros((len(test_imgs), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(test_masks), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "print('Getting test images ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for n in range(len(test_imgs)):\n",
    "    img = imread(test_imgs[n], as_gray=True)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    img[img < threshold_value] = 0\n",
    "    img_resized = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img_resized.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    \n",
    "    mask = imread(test_masks[n], as_gray=True)\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "    mask[mask < threshold_value] = 0\n",
    "    mask_resized = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    Y_test[n] = mask_resized.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "print('Preparing is Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 해볼것이다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 256, 256, 1)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 256, 256, 16)         160       ['lambda[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 256, 256, 16)         64        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 16)         2320      ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 128, 128, 16)         0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 32)         4640      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 128, 128, 32)         0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 128, 128, 32)         128       ['leaky_re_lu[0][0]']         \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 32)         9248      ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 128, 128, 32)         0         ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)           0         ['leaky_re_lu_1[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 64)           0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 64, 64, 64)           256       ['leaky_re_lu_2[0][0]']       \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 64)           36928     ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 64)           0         ['conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 64)           0         ['leaky_re_lu_3[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 128)          0         ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 32, 32, 128)          512       ['leaky_re_lu_4[0][0]']       \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 128)          147584    ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 128)          0         ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 128)          0         ['leaky_re_lu_5[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 16, 16, 256)          1024      ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 256)          590080    ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 32, 32, 128)          131200    ['conv2d_9[0][0]']            \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32, 32, 256)          0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'leaky_re_lu_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 128)          295040    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 32, 32, 128)          0         ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 32, 32, 128)          512       ['leaky_re_lu_6[0][0]']       \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 128)          147584    ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 128)          0         ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 64, 64, 64)           32832     ['leaky_re_lu_7[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'leaky_re_lu_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 64, 64, 64)           73792     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64, 64, 64)           0         ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 64, 64, 64)           256       ['leaky_re_lu_8[0][0]']       \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 64, 64, 64)           36928     ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 128, 128, 32)         8224      ['leaky_re_lu_9[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 128, 128, 64)         0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'leaky_re_lu_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 128, 128, 32)         18464     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 128, 128, 32)         0         ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 128, 128, 32)         128       ['leaky_re_lu_10[0][0]']      \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 32)         9248      ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 128, 128, 32)         0         ['conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 256, 256, 16)         2064      ['leaky_re_lu_11[0][0]']      \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 256, 256, 32)         0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 256, 256, 16)         4624      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 256, 256, 16)         64        ['conv2d_16[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 256, 256, 16)         2320      ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 256, 256, 1)          17        ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1943761 (7.41 MB)\n",
      "Trainable params: 1942289 (7.41 MB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# U-Net model \n",
    "\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255.) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = BatchNormalization() (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = LeakyReLU()(c2)\n",
    "c2 = BatchNormalization() (c2)\n",
    "c2 = Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same') (c2)\n",
    "c2 = LeakyReLU()(c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = LeakyReLU()(c3)\n",
    "c3 = BatchNormalization() (c3)\n",
    "c3 = Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same') (c3)\n",
    "c3 = LeakyReLU()(c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = LeakyReLU()(c4)\n",
    "c4 = BatchNormalization() (c4)\n",
    "c4 = Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same') (c4)\n",
    "c4 = LeakyReLU()(c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = BatchNormalization() (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu',kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "#===========================================\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = LeakyReLU()(c6)\n",
    "c6 = BatchNormalization() (c6)\n",
    "c6 = Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same') (c6)\n",
    "c6 = LeakyReLU()(c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = LeakyReLU()(c7)\n",
    "c7 = BatchNormalization() (c7)\n",
    "c7 = Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same') (c7)\n",
    "c7 = LeakyReLU()(c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = LeakyReLU()(c8)\n",
    "c8 = BatchNormalization() (c8)\n",
    "c8 = Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same') (c8)\n",
    "c8 = LeakyReLU()(c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = BatchNormalization(momentum=0.9) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model.compile(optimizer=Nadam(learning_rate=2e-5), loss='binary_crossentropy', metrics=['binary_accuracy','acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "checkpointer = ModelCheckpoint('model-page.h5', verbose=1, save_best_only=True)\n",
    "reduceLr = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model-page.h5')\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "#픽셀  평가 결과를 0.5의 임계치로 0 or 255로 변환(평가 결과를 바이너리 이미지로 변환).\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# 임의 결과로 하나를 리턴 받아 표시 \n",
    "# ix = random.randint(0, len(preds_test_t))\n",
    "ix = 0\n",
    "print('원본 이미지')\n",
    "imshow(X_test[ix].reshape(IMG_HEIGHT, IMG_WIDTH))\n",
    "plt.show()\n",
    "print('원본 이미지의 세그먼테이션')\n",
    "imshow(Y_test[ix].reshape(IMG_HEIGHT, IMG_WIDTH))\n",
    "plt.show()\n",
    "print('모델의 예측 세그먼테이션')\n",
    "imshow(np.squeeze(preds_test_t[ix].reshape(IMG_HEIGHT, IMG_WIDTH)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
