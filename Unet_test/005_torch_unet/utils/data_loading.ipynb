{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "#데이터 경로 지정  \n",
    "TRAIN_PATH = '../data/'\n",
    "# TEST_PATH = './page_data/test/'\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx].replace('org', 'seg'))\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        # Normalize and resize as necessary\n",
    "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "        # Transform to tensor\n",
    "        image = torch.from_numpy(image).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "\n",
    "        # Rearrange image dimensions to CxHxW\n",
    "        image = image.permute(2, 0, 1) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Define any transforms you want to apply to both images and masks\n",
    "transform = transforms.Compose([\n",
    "    # Add any transformations here\n",
    "])\n",
    "\n",
    "# Initialize your dataset\n",
    "train_dataset = CustomDataset(\n",
    "    image_dir=TRAIN_PATH+'org/',\n",
    "    mask_dir=TRAIN_PATH+'seg/',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Initialize DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    }
   ],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "\n",
    "#데이터 경로 지정  \n",
    "TRAIN_PATH = '../data/'\n",
    "# TEST_PATH = './page_data/test/'\n",
    "\n",
    "# UserWarning을 무시하는 설정(없음 OK)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "\n",
    "#이미지 파일명을 리스트 형식으로 리턴  \n",
    "train_imgs = glob.glob(TRAIN_PATH+'org/*.jpg')\n",
    "train_masks = glob.glob(TRAIN_PATH+'seg/*.jpg')\n",
    "# test_imgs = glob.glob(TEST_PATH+'org/*.jpg')\n",
    "# test_masks = glob.glob(TEST_PATH+'seg/*.jpg')\n",
    "\n",
    "\n",
    "#리스트 길이 리턴  \n",
    "num_of_train_imgs = len(train_imgs)\n",
    "num_of_train_masks = len(train_masks)\n",
    "if num_of_train_imgs != num_of_train_masks:\n",
    "    print('invalid datasets, please check train data')\n",
    "    \n",
    "#각이미지를 배열로 리턴\n",
    "#image \n",
    "X_train = np.zeros((num_of_train_imgs, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "# mask\n",
    "Y_train = np.zeros((num_of_train_masks, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for n in range(num_of_train_imgs):\n",
    "    # 흑백으로 불러와서\n",
    "    # img = cv2.imread(train_imgs[n], cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.imread(train_imgs[n])\n",
    "    # 정규화하고 0~1\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    # 모델에 들어가는 이미지 사이즈로 변경\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "    X_train[n] = img.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    \n",
    "    mask = cv2.imread(train_masks[n])\n",
    "    mask_resized = cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "    Y_train[n] = mask_resized.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
