{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test images ... \n",
      "Preparing is Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras.backend as k\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "\n",
    "#데이터 경로 지정  \n",
    "TRAIN_PATH = './page_data/train/'\n",
    "TEST_PATH = './page_data/test/'\n",
    "\n",
    "# UserWarning을 무시하는 설정(없음 OK)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "\n",
    "#이미지 파일명을 리스트 형식으로 리턴  \n",
    "train_imgs = glob.glob(TRAIN_PATH+'org/*.jpg')\n",
    "train_masks = glob.glob(TRAIN_PATH+'seg/*.jpg')\n",
    "test_imgs = glob.glob(TEST_PATH+'org/*.jpg')\n",
    "test_masks = glob.glob(TEST_PATH+'seg/*.jpg')\n",
    "\n",
    "\n",
    "#리스트 길이 리턴  \n",
    "num_of_train_imgs = len(train_imgs)\n",
    "num_of_train_masks = len(train_masks)\n",
    "if num_of_train_imgs != num_of_train_masks:\n",
    "    print('invalid datasets, please check train data')\n",
    "    \n",
    "#각이미지를 배열로 리턴\n",
    "#image \n",
    "X_train = np.zeros((num_of_train_imgs, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "# mask\n",
    "Y_train = np.zeros((num_of_train_masks, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for n in range(num_of_train_imgs):\n",
    "    # 흑백으로 불러와서\n",
    "    img = imread(train_imgs[n],as_gray=True)\n",
    "    # 정규화하고\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    # 모델에 들어가는 이미지 사이즈로 변경\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    \n",
    "    X_train[n] = img.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    \n",
    "    mask = imread(train_masks[n],as_gray=True)\n",
    "    mask_resized = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    Y_train[n] = mask_resized.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    \n",
    "# 테스트 이미지를 배열로 리턴\n",
    "X_test = np.zeros((len(test_imgs), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(test_masks), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "print('Getting test images ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for n in range(len(test_imgs)):\n",
    "    img = imread(test_imgs[n],as_gray=True)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    \n",
    "    mask = imread(test_masks[n],as_gray=True)\n",
    "    mask_resized = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    Y_test[n] = mask_resized.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "print('Preparing is Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = [os.path.basename(path) for path in train_imgs]\n",
    "# output_file_path = './page_data/pages.txt'\n",
    "# with open(output_file_path, 'w') as file:\n",
    "#     for name in file_names:\n",
    "#         file.write(name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 해볼것이다\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import random\n",
    "\n",
    "import kornia.augmentation as KA\n",
    "import kornia.geometry.transform as KG\n",
    "\n",
    "class DIW(Dataset):\n",
    "    def __init__(self, root_dir, is_train=True, num=0):\n",
    "        super(DIW, self).__init__()\n",
    "        self.is_train = is_train\n",
    "        self.num = num\n",
    "        # load the list of diw images\n",
    "        with open('./page_data/pages.txt', 'r') as fid:\n",
    "            self.X = fid.read().splitlines()\n",
    "        self.X = [root_dir + '/org/' + t + '.jpg' for t in self.X]\n",
    "\n",
    "        with open('./data/bgtex.txt', 'r') as fid:\n",
    "            self.bgtex = fid.read().splitlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.num:\n",
    "            return self.num\n",
    "        else:\n",
    "            return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        t = self.X[index]\n",
    "        im = cv2.imread(t).astype(np.float32) / 255.0\n",
    "        im = im[..., ::-1]\n",
    "\n",
    "        t = t.replace('img', 'seg')\n",
    "        ms = cv2.imread(t).astype(np.float32) / 255.0\n",
    "        ms = np.mean(ms, axis=2, keepdims=True)\n",
    "\n",
    "        # random sample a background image\n",
    "        ind = random.randint(0, len(self.bgtex) - 1)\n",
    "        bg = cv2.imread(self.bgtex[ind]).astype(np.float32) / 255.0\n",
    "        bg = cv2.resize(bg, (200, 200))\n",
    "        bg = np.tile(bg, (3, 3, 1))\n",
    "\n",
    "        im = torch.from_numpy(im.transpose((2, 0, 1)).copy())\n",
    "        ms = torch.from_numpy(ms.transpose((2, 0, 1)).copy())\n",
    "        bg = torch.from_numpy(bg.transpose((2, 0, 1)).copy())\n",
    "\n",
    "        return im, ms, bg\n",
    "\n",
    "class DIWDataAug(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DIWDataAug, self).__init__()\n",
    "        self.cj = KA.ColorJitter(0.1, 0.1, 0.1, 0.1)\n",
    "    \n",
    "    def forward(self, img, ms, bg):\n",
    "        # tight crop\n",
    "        mask = ms[:, 0] > 0.5\n",
    "        \n",
    "        B = img.size(0)\n",
    "        c = torch.randint(20, (B, 5))\n",
    "        img_list = []\n",
    "        msk_list = []\n",
    "        for ii in range(B):\n",
    "            x_img = img[ii]\n",
    "            x_msk = mask[ii]\n",
    "            y, x = x_msk.nonzero(as_tuple=True)\n",
    "            minx = x.min()\n",
    "            maxx = x.max()\n",
    "            miny = y.min()\n",
    "            maxy = y.max()\n",
    "            x_img = x_img[:, miny : maxy + 1, minx : maxx + 1]\n",
    "            x_msk = x_msk[None, miny : maxy + 1, minx : maxx + 1]\n",
    "\n",
    "            # padding\n",
    "            x_img = F.pad(x_img, c[ii, : 4].tolist())\n",
    "            x_msk = F.pad(x_msk, c[ii, : 4].tolist())\n",
    "\n",
    "            # replace bg\n",
    "            if c[ii][-1] > 2:\n",
    "                x_bg = bg[ii][:, :x_img.size(1), :x_img.size(2)]\n",
    "            else:\n",
    "                x_bg = torch.ones_like(x_img) * torch.rand((3, 1, 1), device=x_img.device)\n",
    "            x_msk = x_msk.float()\n",
    "            x_img = x_img * x_msk + x_bg * (1. - x_msk)\n",
    "\n",
    "            # resize\n",
    "            x_img = KG.resize(x_img[None, :], (256, 256))\n",
    "            x_msk = KG.resize(x_msk[None, :], (64, 64))\n",
    "            img_list.append(x_img)\n",
    "            msk_list.append(x_msk)\n",
    "        img = torch.cat(img_list)\n",
    "        msk = torch.cat(msk_list)\n",
    "        # jitter color\n",
    "        img = self.cj(img)\n",
    "        return img, msk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋과 데이터 증강 모듈 초기화\n",
    "root_dir = './page_data/train/'\n",
    "dataset = DIW(root_dir, is_train=True)\n",
    "data_aug = DIWDataAug()\n",
    "\n",
    "# DataLoader를 통해 데이터셋 로드\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# 데이터 증강을 적용하여 배치 처리\n",
    "for im, ms, bg in dataloader:\n",
    "    augmented_im, augmented_ms = data_aug(im, ms, bg)\n",
    "    # 이제 augmented_im과 augmented_ms를 사용하여 트레이닝 수행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
