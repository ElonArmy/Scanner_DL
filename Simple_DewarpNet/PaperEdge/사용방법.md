# PE 실행방법
- [Enet](https://drive.google.com/file/d/1OVHETBHQ5u-1tnci3qd7OcAjas4v1xnl/view?usp=sharing), [Tnet](https://drive.google.com/file/d/1gEp4ecmdvKds2nzk9CaZb_pLvhRoyAsv/view?usp=sharing)
- 사전학습 모델을 models 폴더에 넣는다.
- 가상환경에 설치된 파이토치의 rcf_env/Lib/site-packages/torch/functional.py에서 line 504근처의 def _meshgridd의  return을 수정해야됨
    ```
    return _VF.meshgrid(tensors, **kwargs, indexing="ij")
    ```
- 가상환경 실행
- 경로 이동 후
```
python demo.py --img_path 'images/IMG_2453.jpg'
```
- IMG_2453를 원하는 이미지로 변경해서 확인
- test.ipynb에서 jupyter로 확인가능



## 방법

### 함수 설명
- 원본이미지가 x이고 unwarping 결과물이 $x_t$일 때 $$x_t = \phi(\phi(x,d_E),d_T)$$
- 2D 와핑함수 $\phi(a1,a2)$가 있을때 a2의 변형 필드(=이하 변형그리드)를 기반으로 a1을 변형한다. 
- $d_E$는 ENet에서 나온 경계기반변형그리드, $d_T$는 TNet의 텍스쳐기반변형그리드이다
- 변형 필드란 쉽게 말해 원본이미지에서 어느 위치의 픽셀값을 가져와야하는지 알려주는 것이다. 역방향 매핑이란 이런 샘플링 위치를 결정하는 하나의 방법이다

### ENet 아키텍처 설명
- FCN구조, factor of 2(가로축, 세로축)의 특징맵을 샘플링하는 residual block을 사용하는 인코더와 디코더로 이루어짐
- 256*256*5 인 ENet 입력 텐서는 이미지의 RGB와 coordinates(좌표)가 합쳐진것이다
- d* 는 원본이미지에서 인공적으로 만든 변형필드인데 (N*N*2)차원이며 크기는 $d_E$와 동일하다. ENet에서는 $d_E$와 $d*$의 경계요소를 맞추도록 학습시킨다.
- 손실함수 $$L_{SE} = |B(d_E)-B(d*)|_1$$
- B()는 변형필드에서 경계를 추출하는 함수이다. 즉 변형필드의 경계요소만으로도 문서에 포함되는 모든 픽셀 샘플위치를 추정할수있으며, 선형보간으로 복원하는게 가능하다는것이다
- 현실 문서의 마스크 이미지를 약한 지도학습에 사용한다
- 손실함수 $$L_M=|\phi(y,d_E)-m|_1$$
- d_E가 ENet의 출력된 변형필드이고, m은 사각형 마스크이미지이다.
- 그러나 위의 손실함수는 단순히 경계를 늘리는 것에대한 손실함수이고 현실의 문서가 복원되는 정확한 정보에 대해서는 부정확하다. 따라서 a cycle-consistent segmentation mask loss라는 손실함수를 사용해야한다. $$L_M=|\phi(y,d_E)-m|_1 + |\phi(m,d^{-1}_{E}-y)|_1$$
- $d^{-1}_{E}$는 $d_E$의 뒤집어진 변형필드이다. 아무튼 이런 역방향 변형필드를 만들어서 다항하모닉 스플라인 어쩌구 함수를 만들어 사용할수있다고 한다(어려워서 중략)
- 즉, 사각형 마스크에 변형필드를 적용해 이미지의 찌그러진 문서를 만들어내서 정방향 변형과 손실함수를 비교하면서 문서내부의 정보를 잃지 않는다는 것인듯.


### 모델학습한 방법
- 현실 문서의 annotation인 DIW 5000개와 인조적인 Doc3D데이터 8만8천개를 학습시킴
- 인조의 데이터만 학습 시키는 것은 어느 수준을 넘어가면 정확도가 향상되지 않는다. 따라서 현실의 데이터가 효과적으로 도메인갭을 보완해준다
- ENet은 doc3d(인조)데이터셋으로 학습된 모델에 diw(현실) 데이터셋이 파인튜닝된것이다.
- 그 이후, ENet의 가중치는 고정되고, 해당 출력으로 TNet을 학습하는 과정을 거친다
- 미작성

### 한계
- 문서의 본래 3D 형태를 알지못하는 방법론이다