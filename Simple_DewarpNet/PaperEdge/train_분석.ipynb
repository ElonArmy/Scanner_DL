{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파인튜닝 하기위한 분석 \n",
    "- 파인튜닝에 사용하지않는 코드는 정리했다\n",
    "- 파서를 사용하지않고 주피터에 편하게 명시적으로 지정한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 파이토치 모델 학습을 돕는 라이브러리\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import RunningAverage\n",
    "\n",
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "cv2.setNumThreads(0)\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "# import pickle\n",
    "from handlers import VisPlot, CSVLogger\n",
    "from networks import GlobalWarper, LocalWarper, MaskLoss, WarperUtil, LocalLoss, SupervisedLoss\n",
    "\n",
    "# 학습또는 검증 데이터셋 불러오기, 데이터증강\n",
    "# doc3d데이터와 diw데이터 두개를 사용한다.\n",
    "# from doc3d import Doc3D, Doc3DDataAug   # 데이터 링크소실됨\n",
    "from diw import DIW, DIWDataAug\n",
    "\n",
    "# 파인튜닝하여 사용해볼것이기때문에 doc3d는 생략\\\n",
    "    \n",
    "\n",
    "G_Path = './models/G_w_checkpoint_13820.pt'\n",
    "exp_dir = './chck/'\n",
    "\n",
    "vis_port = 10086\n",
    "vis_freq = 100\n",
    "brief = 'demo training'\n",
    "    \n",
    "# 구성 파싱해오기(경로)\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--config\", required=True, type=str, help=\"experiment configuration files.\")\n",
    "# exp_config = parser.parse_args().config\n",
    "# with open('configs/' + exp_config, 'r') as fid:\n",
    "#     args = json.load(fid)\n",
    "# print(args)\n",
    "# Path(args['exp_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# netG == Enet\n",
    "# netL == Tnet이다\n",
    "netG = GlobalWarper().to(device)\n",
    "# netL = LocalWarper().to(device)\n",
    "\n",
    "# 이미지변환, 정규화하는 인스턴스\n",
    "warpUtil = WarperUtil(64).to(device)\n",
    "#지도학습 손실계산인스턴스\n",
    "spvLoss = SupervisedLoss().to(device)\n",
    "# netL 손실계산 인스턴스\n",
    "# local_loss = LocalLoss()\n",
    "\n",
    "# 사전학습 가중치 가져오기\n",
    "# if args['G_ckpt']:\n",
    "    # netG.load_state_dict(torch.load(args['G_ckpt'])['G'])\n",
    "    \n",
    "netG.load_state_dict(torch.load(G_Path, map_location=device)['G'])\n",
    "# if args['L_ckpt']:\n",
    "#     netL.load_state_dict(torch.load(args['L_ckpt'])['L'])\n",
    "\n",
    "# 옵티마이저 생성\n",
    "lr_G = 1e-5  # 파인튜닝할때 사용한 learning_rate\n",
    "optimizer_G = Adam(netG.parameters(), lr=lr_G)\n",
    "# optimizer_L = Adam(netL.parameters(), lr=args['lr_L'])\n",
    "\n",
    "\n",
    "# 스케줄러: 검증손실이 개선되지않을때 확습률 조절\n",
    "scheduler_G = ReduceLROnPlateau(optimizer_G, factor=0.1, patience=2, verbose=True)\n",
    "# scheduler_L = ReduceLROnPlateau(optimizer_L, factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# 마스크 손실함수(크기)\n",
    "mask_loss = MaskLoss(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/diw_5k.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      3\u001b[0m diw_root \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./images/data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m trn_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mDIW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiw_root\u001b[49m\u001b[43m)\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# trn_loader = DataLoader(MixDataset(Doc3D(root_dir=args['doc3d_root']), DIW(root_dir=args['diw'])), batch_size=args['batch_size'], shuffle=True, num_workers=8, pin_memory=True)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(DIW(root_dir\u001b[38;5;241m=\u001b[39mdiw_root, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\82105\\Desktop\\book_scan\\Simple_DewarpNet\\PaperEdge\\diw.py:21\u001b[0m, in \u001b[0;36mDIW.__init__\u001b[1;34m(self, root_dir, is_train, num)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum \u001b[38;5;241m=\u001b[39m num\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# load the list of diw images\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/diw_5k.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m fid\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m [root_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/img/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m t \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/diw_5k.txt'"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "diw_root ='./images/data/'\n",
    "\n",
    "trn_loader = DataLoader(DIW(root_dir=diw_root), batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "# trn_loader = DataLoader(MixDataset(Doc3D(root_dir=args['doc3d_root']), DIW(root_dir=args['diw'])), batch_size=args['batch_size'], shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(DIW(root_dir=diw_root, is_train=False), batch_size=batch_size, num_workers=8, pin_memory=True)\n",
    "\n",
    "# 데이터 증강시행\n",
    "diw_aug = DIWDataAug()\n",
    "\n",
    "# 데모실행에 사용할 id\n",
    "model_id = 'demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step with a \"_s\" postfix is for supervised training with doc3d data.\n",
    "# training step with a \"_w\" postfix is for weakly supervised training with both\n",
    "# doc3d and diw data.\n",
    "# 따라서 우린 파인튜닝하기위해 train_G_step_s와 train_G_step_w 만 사용할것이다\n",
    "def train_G_step_s(engine, batch):\n",
    "    '''\n",
    "    엔진과, 미니배치를 입력받는다\n",
    "    '''\n",
    "    netG.train()  # 학습모드로 실행\n",
    "    im, fm, bm, bg = batch  # 배치에서 이미지, 마스크, 바운더리맵, 배경이미지\n",
    "    im = im.to(device)\n",
    "    fm = fm.to(device)\n",
    "    bm = bm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad(): # 그래디언트 계산안함\n",
    "        # 데이터증강후 x_train, y_train를얻는다\n",
    "        x, y = doc3d_aug(im, fm, bm, bg)  \n",
    "    netG.zero_grad()  #그래디언트 초기화\n",
    "    d = netG(x)   # 입력데이터 x를넣어서 예측계산\n",
    "    loss = spvLoss.gloss(d, y)  # 실제데이터 y와 손실을 계산\n",
    "    loss.backward()  # 역전파하여 구래디언트계산 및 가중치 업데이트\n",
    "    optimizer_G.step()   # 옵치마이저로 가중치 업데이트\n",
    "    dd = warpUtil.global_post_warp(d, 64)  # d를 global 워핑해서 dd를 얻음\n",
    "    # 보간하여 256크기로 변환, 코너를 정렬한다\n",
    "    d = F.interpolate(dd, size=256, mode='bilinear', align_corners=True)\n",
    "    # d를 사용해 격자 샘플링하여 fake_x생성 detach해서 그래디언트가 전파하지않게 설정\n",
    "    fake_x = F.grid_sample(x, d.permute(0, 2, 3, 1), align_corners=True).detach()\n",
    "    # 엔진 상태에다가 생성된 이미지를 저장\n",
    "    engine.state.img = [x, fake_x]\n",
    "    # 학습단계에서 계산한 손실을 반환\n",
    "    return {'loss_G': loss.item()}\n",
    "\n",
    "def validate_G_step_s(engine, batch):\n",
    "    '''\n",
    "    Enet 학습하는함수\n",
    "    학습한 모델의 성능을 평가하는것이다\n",
    "    맨뒤 s는 supervised 지도학습을 의미한다\n",
    "    '''\n",
    "    netG.eval()  # 검증모드로 변경\n",
    "    im, fm, bm, bg = batch\n",
    "    im = im.to(device)\n",
    "    fm = fm.to(device)\n",
    "    bm = bm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad():\n",
    "        x, y = doc3d_aug(im, fm, bm, bg)\n",
    "        d = netG(x)  \n",
    "        loss = spvLoss.gloss(d, y)\n",
    "        # 엔진 상태에 검증 손실을 누적 시킨다\n",
    "        engine.state.val_loss += loss.item()\n",
    "        #  검증 단계에서 계산한 손실을 반환\n",
    "        return {'loss_G': loss.item()}\n",
    "    \n",
    "\n",
    "def train_G_step_w(engine, batch):\n",
    "    '''\n",
    "    \"weakly supervised\" 약한 지도학습을 뜻한다\n",
    "    Semantic Segmentation에서는 픽셀 단위로 정확한 레이블이 아닌 \n",
    "    이미지 내에서 특정 객체 또는 클래스가 존재하는 영역을 알려주는 경우\n",
    "    즉 마스크이미지로 학습하는것이다\n",
    "    '''\n",
    "    # doc3d data\n",
    "    loss0 = train_G_step_s(engine, batch[0])['loss_G']\n",
    "    # diw data\n",
    "    x, xm, bg = batch[1]\n",
    "    x = x.to(device)\n",
    "    xm = xm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad():\n",
    "        x, xm = diw_aug(x, xm, bg)\n",
    "    netG.zero_grad()\n",
    "    d = netG(x)\n",
    "    dd = F.interpolate(d, 64, mode='bilinear', align_corners=True)\n",
    "    loss1, _ = mask_loss(dd, xm, 64)\n",
    "    # weight\n",
    "    loss1 *= 0.1\n",
    "    loss1.backward()\n",
    "    optimizer_G.step()\n",
    "    dd = warpUtil.global_post_warp(d, 64)\n",
    "    d = F.interpolate(dd, size=256, mode='bilinear', align_corners=True)\n",
    "    fake_x = F.grid_sample(x, d.permute(0, 2, 3, 1), align_corners=True).detach()\n",
    "    engine.state.img = [x, fake_x, xm]\n",
    "    return {'loss0': loss0, 'loss1': loss1.item()}\n",
    "\n",
    "# 학습기\n",
    "# trainer = Engine(train_G_step_s)\n",
    "# trainer = Engine(train_L_step_s)\n",
    "trainer = Engine(train_G_step_w)\n",
    "# trainer = Engine(train_L_step_w)\n",
    "# trainer.state.metrics['loss_val'] = 0\n",
    "\n",
    "\n",
    "# 검증기 => 파인튜닝에 사용하진 않는다\n",
    "validator = Engine(validate_G_step_s)\n",
    "\n",
    "# validator = Engine(validate_L_step_s)\n",
    "\n",
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "# def validate(engine):\n",
    "#     validator.state.val_loss = 0\n",
    "#     validator.run(val_loader)\n",
    "#     val_loss = validator.state.val_loss / len(val_loader)\n",
    "#     trainer.state.metrics['loss_val'] = val_loss\n",
    "#     print(f'Validation loss: {val_loss}')\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def update_lr(engine):\n",
    "    scheduler_G.step(engine.state.metrics['loss_val'])\n",
    "    # scheduler_L.step(engine.state.metrics['loss_val'])\n",
    "\n",
    "RunningAverage(alpha=0.9, output_transform=lambda x: x['loss_G']).attach(trainer, 'loss_G')\n",
    "# RunningAverage(alpha=0.9, output_transform=lambda x: x['loss_L']).attach(trainer, 'loss_L')\n",
    "# RunningAverage(alpha=0.9, output_transform=lambda x: x['loss0']).attach(trainer, 'loss0')\n",
    "# RunningAverage(alpha=0.9, output_transform=lambda x: x['loss1']).attach(trainer, 'loss1')\n",
    "\n",
    "\n",
    "\n",
    "monitoring_metrics = ['loss_G']\n",
    "# monitoring_metrics = ['loss_L']\n",
    "# monitoring_metrics = ['loss0', 'loss1']\n",
    "\n",
    "# model checkpoint\n",
    "ckpt_hdl = ModelCheckpoint(args['exp_dir'], model_id, n_saved=1, require_empty=False, score_function=lambda x: -x.state.metrics['loss_val'])\n",
    "# ckpt_hdl = ModelCheckpoint(args['exp_dir'], model_id, n_saved=3, require_empty=False)\n",
    "# test on same images\n",
    "vis_plot = VisPlot(port=args['vis_port'], env='gnet')\n",
    "# attach progress bar\n",
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(trainer, metric_names=monitoring_metrics)\n",
    "# vpbar = ProgressBar()\n",
    "# vpbar.attach(validator)\n",
    "# log csv\n",
    "csv_logger = CSVLogger(os.path.join(args['exp_dir'], 'log_' + model_id + '.csv'))\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED(every=5), ckpt_hdl, {'G': netG, 'L': netL})\n",
    "# trainer.add_event_handler(Events.EPOCH_COMPLETED, tst_vis())\n",
    "\n",
    "# vis\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=args['vis_freq']))\n",
    "def plot_input_output():\n",
    "    for ii in range(len(trainer.state.img)):\n",
    "        vis_plot.plot_imgs(trainer.state.img[ii][:min(16, args['batch_size'])].cpu().numpy(), win=f'img{ii}')\n",
    "    # # plot mesh\n",
    "    # tt = trainer.state.img[-1][:2].permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    # vis_plot.plot_meshes(tt, win='mesh1')\n",
    "    # tt = trainer.state.img[-1][:2].permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    # vis_plot.plot_meshes(tt, win='mesh2')\n",
    "    # fig, axs = plt.subplots(1, 8)\n",
    "    # tt = trainer.state.img[-1][:8].permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    # plt.clf()\n",
    "    # for ii in range(8):\n",
    "    #     t = tt[ii]\n",
    "    #     axs[ii].pcolormesh(t[..., 0], t[..., 1], np.zeros_like(t[..., 0]), edgecolors='r')\n",
    "    #     axs[ii].invert_yaxis()\n",
    "    #     axs[ii].axis('equal')\n",
    "    # vis.matplot(plt, env='gnet', win='mpl')\n",
    "\n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED(every=args['vis_freq']), vis_plot.plot_loss, monitoring_metrics)\n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED(every=args['vis_freq']), csv_logger, monitoring_metrics)\n",
    "\n",
    "\n",
    "trainer.run(trn_loader, max_epochs=args['epochs'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
