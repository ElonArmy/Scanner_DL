{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 파이토치 모델 학습을 돕는 라이브러리\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import RunningAverage\n",
    "\n",
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "cv2.setNumThreads(0)\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "# import pickle\n",
    "from handlers import VisPlot, CSVLogger\n",
    "from networks import GlobalWarper, LocalWarper, MaskLoss, WarperUtil, LocalLoss, SupervisedLoss\n",
    "\n",
    "# 학습또는 검증 데이터셋 불러오기, 데이터증강\n",
    "# doc3d데이터와 diw데이터 두개를 사용한다.\n",
    "# from doc3d import Doc3D, Doc3DDataAug   # 데이터 링크소실됨\n",
    "from diw import DIW, DIWDataAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --config CONFIG\n",
      "ipykernel_launcher.py: error: the following arguments are required: --config\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# 구성 파싱해오기(경로)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", required=True, type=str, help=\"experiment configuration files.\")\n",
    "exp_config = parser.parse_args().config\n",
    "with open('configs/' + exp_config, 'r') as fid:\n",
    "    args = json.load(fid)\n",
    "print(args)\n",
    "Path(args['exp_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# netG == Enet\n",
    "# netL == Tnet이다\n",
    "netG = GlobalWarper().to(device)\n",
    "netL = LocalWarper().to(device)\n",
    "\n",
    "# 이미지변환, 정규화하는 인스턴스\n",
    "warpUtil = WarperUtil(64).to(device)\n",
    "#지도학습 손실계산인스턴스\n",
    "spvLoss = SupervisedLoss().to(device)\n",
    "# netL 손실계산 인스턴스\n",
    "local_loss = LocalLoss()\n",
    "\n",
    "# 사전학습 가중치 가져오기\n",
    "if args['G_ckpt']:\n",
    "    netG.load_state_dict(torch.load(args['G_ckpt'])['G'])\n",
    "if args['L_ckpt']:\n",
    "    netL.load_state_dict(torch.load(args['L_ckpt'])['L'])\n",
    "\n",
    "# 옵티마이저 생성\n",
    "optimizer_G = Adam(netG.parameters(), lr=args['lr_G'])\n",
    "optimizer_L = Adam(netL.parameters(), lr=args['lr_L'])\n",
    "\n",
    "\n",
    "# 스케줄러: 검증손실이 개선되지않을때 확습률 조절\n",
    "scheduler_G = ReduceLROnPlateau(optimizer_G, factor=0.1, patience=2, verbose=True)\n",
    "scheduler_L = ReduceLROnPlateau(optimizer_L, factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# 마스크 손실함수(크기)\n",
    "mask_loss = MaskLoss(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    doc3d데이터와 diw 데이터를 섞어서 데이터셋을 다시 만든다\n",
    "    '''\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __getitem__(self, ii):\n",
    "        len_diw = len(self.datasets[1])\n",
    "        jj = ii % len_diw\n",
    "        # return self.datasets[1][jj]\n",
    "        return self.datasets[0][ii], self.datasets[1][jj]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datasets[0])\n",
    "\n",
    "# trn_loader = DataLoader(Doc3D(root_dir=args['doc3d_root']), batch_size=args['batch_size'], shuffle=True, num_workers=8, pin_memory=True)\n",
    "# trn_loader = DataLoader(MixDataset(Doc3D(root_dir=args['doc3d_root']), DIW(root_dir=args['diw'])), batch_size=args['batch_size'], shuffle=True, num_workers=8, pin_memory=True)\n",
    "# val_loader = DataLoader(Doc3D(root_dir=args['doc3d_root'], is_train=False), batch_size=args['batch_size'], num_workers=8, pin_memory=True)\n",
    "\n",
    "# doc3d_aug = Doc3DDataAug()\n",
    "# 데이터 증강시행\n",
    "diw_aug = DIWDataAug()\n",
    "\n",
    "# 데모실행에 사용할 id\n",
    "model_id = 'demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step with a \"_s\" postfix is for supervised training with doc3d data.\n",
    "# training step with a \"_w\" postfix is for weakly supervised training with both\n",
    "# doc3d and diw data.\n",
    "def train_G_step_s(engine, batch):\n",
    "    '''\n",
    "    엔진과, 미니배치를 입력받는다\n",
    "    '''\n",
    "    netG.train()  # 학습모드로 실행\n",
    "    im, fm, bm, bg = batch  # 배치에서 이미지, 마스크, 바운더리맵, 배경이미지\n",
    "    im = im.to(device)\n",
    "    fm = fm.to(device)\n",
    "    bm = bm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad(): # 그래디언트 계산안함\n",
    "        # 데이터증강후 x_train, y_train를얻는다\n",
    "        x, y = doc3d_aug(im, fm, bm, bg)  \n",
    "    netG.zero_grad()  #그래디언트 초기화\n",
    "    d = netG(x)   # 입력데이터 x를넣어서 예측계산\n",
    "    loss = spvLoss.gloss(d, y)  # 실제데이터 y와 손실을 계산\n",
    "    loss.backward()  # 역전파하여 구래디언트계산 및 가중치 업데이트\n",
    "    optimizer_G.step()   # 옵치마이저로 가중치 업데이트\n",
    "    dd = warpUtil.global_post_warp(d, 64)  # d를 global 워핑해서 dd를 얻음\n",
    "    # 보간하여 256크기로 변환, 코너를 정렬한다\n",
    "    d = F.interpolate(dd, size=256, mode='bilinear', align_corners=True)\n",
    "    # d를 사용해 격자 샘플링하여 fake_x생성 detach해서 그래디언트가 전파하지않게 설정\n",
    "    fake_x = F.grid_sample(x, d.permute(0, 2, 3, 1), align_corners=True).detach()\n",
    "    # 엔진 상태에다가 생성된 이미지를 저장\n",
    "    engine.state.img = [x, fake_x]\n",
    "    # 학습단계에서 계산한 손실을 반환\n",
    "    return {'loss_G': loss.item()}\n",
    "\n",
    "def validate_G_step_s(engine, batch):\n",
    "    '''\n",
    "    Enet 학습하는함수\n",
    "    학습한 모델의 성능을 평가하는것이다\n",
    "    맨뒤 s는 supervised 지도학습을 의미한다\n",
    "    '''\n",
    "    netG.eval()  # 검증모드로 변경\n",
    "    im, fm, bm, bg = batch\n",
    "    im = im.to(device)\n",
    "    fm = fm.to(device)\n",
    "    bm = bm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad():\n",
    "        x, y = doc3d_aug(im, fm, bm, bg)\n",
    "        d = netG(x)  \n",
    "        loss = spvLoss.gloss(d, y)\n",
    "        # 엔진 상태에 검증 손실을 누적 시킨다\n",
    "        engine.state.val_loss += loss.item()\n",
    "        #  검증 단계에서 계산한 손실을 반환\n",
    "        return {'loss_G': loss.item()}\n",
    "    \n",
    "def train_L_step_s(engine, batch):\n",
    "    '''\n",
    "    Tnet 학습하는 함수\n",
    "    '''\n",
    "    netL.train()\n",
    "    im, fm, bm, bg = batch\n",
    "    im = im.to(device)\n",
    "    fm = fm.to(device)\n",
    "    bm = bm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad():\n",
    "        x, y = doc3d_aug(im, fm, bm, bg)\n",
    "    # pass the global warp net\n",
    "        netG.eval()\n",
    "        dg = netG(x)\n",
    "        dg = warpUtil.global_post_warp(dg, 64)\n",
    "        gs = F.interpolate(dg, 256, mode='bilinear', align_corners=True)\n",
    "        xg = F.grid_sample(x, gs.permute(0, 2, 3, 1), align_corners=True)\n",
    "    netL.zero_grad()\n",
    "    xd = netL(xg)\n",
    "    loss, _ = spvLoss.lloss(xd, y, dg)\n",
    "    loss.backward()\n",
    "    optimizer_L.step()\n",
    "    fake_x = F.grid_sample(xg, F.interpolate(xd, 256, mode='bilinear', align_corners=True).permute(0, 2, 3, 1), align_corners=True)\n",
    "    engine.state.img = [x, xg.detach(), fake_x.detach()]\n",
    "    return {'loss_L': loss.item()}\n",
    "\n",
    "def validate_L_step_s(engine, batch):\n",
    "    im, fm, bm, bg = batch\n",
    "    im = im.to(device)\n",
    "    fm = fm.to(device)\n",
    "    bm = bm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad():\n",
    "        x, y = doc3d_aug(im, fm, bm, bg)\n",
    "        netG.eval()\n",
    "        netL.eval()\n",
    "        dg = netG(x)\n",
    "        dg = warpUtil.global_post_warp(dg, 64)\n",
    "        gs = F.interpolate(dg, 256, mode='bilinear', align_corners=True)\n",
    "        xg = F.grid_sample(x, gs.permute(0, 2, 3, 1), align_corners=True)\n",
    "        xd = netL(xg)\n",
    "        loss, _ = spvLoss.lloss(xd, y, dg)\n",
    "        engine.state.val_loss += loss.item()\n",
    "        return {'loss_L': loss.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_G_step_w(engine, batch):\n",
    "    '''\n",
    "    \"weakly supervised\" 약한 지도학습을 뜻한다\n",
    "    Semantic Segmentation에서는 픽셀 단위로 정확한 레이블이 아닌 \n",
    "    이미지 내에서 특정 객체 또는 클래스가 존재하는 영역을 알려주는 경우\n",
    "    즉 마스크이미지로 학습하는것이다\n",
    "    '''\n",
    "    # doc3d data\n",
    "    loss0 = train_G_step_s(engine, batch[0])['loss_G']\n",
    "    # diw data\n",
    "    x, xm, bg = batch[1]\n",
    "    x = x.to(device)\n",
    "    xm = xm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad():\n",
    "        x, xm = diw_aug(x, xm, bg)\n",
    "    netG.zero_grad()\n",
    "    d = netG(x)\n",
    "    dd = F.interpolate(d, 64, mode='bilinear', align_corners=True)\n",
    "    loss1, _ = mask_loss(dd, xm, 64)\n",
    "    # weight\n",
    "    loss1 *= 0.1\n",
    "    loss1.backward()\n",
    "    optimizer_G.step()\n",
    "    dd = warpUtil.global_post_warp(d, 64)\n",
    "    d = F.interpolate(dd, size=256, mode='bilinear', align_corners=True)\n",
    "    fake_x = F.grid_sample(x, d.permute(0, 2, 3, 1), align_corners=True).detach()\n",
    "    engine.state.img = [x, fake_x, xm]\n",
    "    return {'loss0': loss0, 'loss1': loss1.item()}\n",
    "\n",
    "def train_L_step_w(engine, batch):\n",
    "    '''\n",
    "    doc3d, diw데이터 둘다 사용해서 Enet학습시키고\n",
    "    doc3d는 약한지도학습으로 Enet을 학습시키고\n",
    "    diw는 학습된 Enet으로 이미지를 먼저 변환하고 Tnet을 학습시킨다\n",
    "    '''\n",
    "    # doc3d data\n",
    "    netL.train()\n",
    "    im, fm, bm, bg = batch[0]\n",
    "    im = im.to(device)\n",
    "    fm = fm.to(device)\n",
    "    bm = bm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad():\n",
    "        x, y = doc3d_aug(im, fm, bm, bg)\n",
    "    # pass the global warp net\n",
    "        netG.eval()\n",
    "        dg = netG(x)\n",
    "        dg = warpUtil.global_post_warp(dg, 64)\n",
    "        gs = F.interpolate(dg, 256, mode='bilinear', align_corners=True)\n",
    "        xg = F.grid_sample(x, gs.permute(0, 2, 3, 1), align_corners=True)\n",
    "    netL.zero_grad()\n",
    "    xd = netL(xg)\n",
    "    loss0, xdh = spvLoss.lloss(xd, y, dg)\n",
    "    loss0.backward()\n",
    "    optimizer_L.step()\n",
    "\n",
    "    # diw data\n",
    "    x, xm, bg = batch[1]\n",
    "    x = x.to(device)\n",
    "    xm = xm.to(device)\n",
    "    bg = bg.to(device)\n",
    "    with torch.no_grad():\n",
    "        x, xm = diw_aug(x, xm, bg)\n",
    "        netG.eval()\n",
    "        dg = netG(x)\n",
    "        dg = warpUtil.global_post_warp(dg, 64)\n",
    "        gs = F.interpolate(dg, 256, mode='bilinear', align_corners=True)\n",
    "        x = F.grid_sample(x, gs.permute(0, 2, 3, 1), align_corners=True)\n",
    "    # generate warp\n",
    "    tgs, invtgs = warpUtil.perturb_warp(xdh)\n",
    "    xp = F.grid_sample(x, F.interpolate(tgs, 256, mode='bilinear', align_corners=True).permute(0, 2, 3, 1), align_corners=True)\n",
    "    netL.zero_grad()\n",
    "    xd = netL(x)\n",
    "    xpd = netL(xp.detach())\n",
    "    loss1 = local_loss.warp_diff_loss(xd, xpd, tgs.detach(), invtgs.detach())\n",
    "    loss1 *= 0.1\n",
    "    loss1.backward()\n",
    "    optimizer_L.step()\n",
    "    fake_x = F.grid_sample(x, F.interpolate(xd, 256, mode='bilinear', align_corners=True).permute(0, 2, 3, 1), align_corners=True)\n",
    "    fake_xp = F.grid_sample(xp, F.interpolate(xpd, 256, mode='bilinear', align_corners=True).permute(0, 2, 3, 1), align_corners=True)\n",
    "    engine.state.img = [x.detach(), xp.detach(), fake_x.detach(), fake_xp.detach()]\n",
    "    return {'loss0': loss0, 'loss1': loss1.item()}\n",
    "\n",
    "# 학습기\n",
    "trainer = Engine(train_G_step_s)\n",
    "# trainer = Engine(train_L_step_s)\n",
    "# trainer = Engine(train_G_step_w)\n",
    "# trainer = Engine(train_L_step_w)\n",
    "# trainer.state.metrics['loss_val'] = 0\n",
    "\n",
    "\n",
    "# 검증기\n",
    "validator = Engine(validate_G_step_s)\n",
    "# validator = Engine(validate_L_step_s)\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def validate(engine):\n",
    "    validator.state.val_loss = 0\n",
    "    validator.run(val_loader)\n",
    "    val_loss = validator.state.val_loss / len(val_loader)\n",
    "    trainer.state.metrics['loss_val'] = val_loss\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def update_lr(engine):\n",
    "    scheduler_G.step(engine.state.metrics['loss_val'])\n",
    "    # scheduler_L.step(engine.state.metrics['loss_val'])\n",
    "\n",
    "RunningAverage(alpha=0.9, output_transform=lambda x: x['loss_G']).attach(trainer, 'loss_G')\n",
    "# RunningAverage(alpha=0.9, output_transform=lambda x: x['loss_L']).attach(trainer, 'loss_L')\n",
    "# RunningAverage(alpha=0.9, output_transform=lambda x: x['loss0']).attach(trainer, 'loss0')\n",
    "# RunningAverage(alpha=0.9, output_transform=lambda x: x['loss1']).attach(trainer, 'loss1')\n",
    "\n",
    "\n",
    "\n",
    "monitoring_metrics = ['loss_G']\n",
    "# monitoring_metrics = ['loss_L']\n",
    "# monitoring_metrics = ['loss0', 'loss1']\n",
    "\n",
    "# model checkpoint\n",
    "ckpt_hdl = ModelCheckpoint(args['exp_dir'], model_id, n_saved=1, require_empty=False, score_function=lambda x: -x.state.metrics['loss_val'])\n",
    "# ckpt_hdl = ModelCheckpoint(args['exp_dir'], model_id, n_saved=3, require_empty=False)\n",
    "# test on same images\n",
    "vis_plot = VisPlot(port=args['vis_port'], env='gnet')\n",
    "# attach progress bar\n",
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(trainer, metric_names=monitoring_metrics)\n",
    "# vpbar = ProgressBar()\n",
    "# vpbar.attach(validator)\n",
    "# log csv\n",
    "csv_logger = CSVLogger(os.path.join(args['exp_dir'], 'log_' + model_id + '.csv'))\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED(every=5), ckpt_hdl, {'G': netG, 'L': netL})\n",
    "# trainer.add_event_handler(Events.EPOCH_COMPLETED, tst_vis())\n",
    "\n",
    "# vis\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=args['vis_freq']))\n",
    "def plot_input_output():\n",
    "    for ii in range(len(trainer.state.img)):\n",
    "        vis_plot.plot_imgs(trainer.state.img[ii][:min(16, args['batch_size'])].cpu().numpy(), win=f'img{ii}')\n",
    "    # # plot mesh\n",
    "    # tt = trainer.state.img[-1][:2].permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    # vis_plot.plot_meshes(tt, win='mesh1')\n",
    "    # tt = trainer.state.img[-1][:2].permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    # vis_plot.plot_meshes(tt, win='mesh2')\n",
    "    # fig, axs = plt.subplots(1, 8)\n",
    "    # tt = trainer.state.img[-1][:8].permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    # plt.clf()\n",
    "    # for ii in range(8):\n",
    "    #     t = tt[ii]\n",
    "    #     axs[ii].pcolormesh(t[..., 0], t[..., 1], np.zeros_like(t[..., 0]), edgecolors='r')\n",
    "    #     axs[ii].invert_yaxis()\n",
    "    #     axs[ii].axis('equal')\n",
    "    # vis.matplot(plt, env='gnet', win='mpl')\n",
    "\n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED(every=args['vis_freq']), vis_plot.plot_loss, monitoring_metrics)\n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED(every=args['vis_freq']), csv_logger, monitoring_metrics)\n",
    "\n",
    "\n",
    "trainer.run(trn_loader, max_epochs=args['epochs'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
